{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.gyazo.com/414881441edbabcf2ab32d3bdfc1711e.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "from tqdm import tqdm\n",
    "\n",
    "unk = \"<UNK>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consult the PyTorch documentation for information on the functions used below:\n",
    "# https://pytorch.org/docs/stable/torch.html\n",
    "\n",
    "class FFNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, h):\n",
    "        super(FFNN, self).__init__()\n",
    "        \n",
    "        self.h = h\n",
    "        self.W1 = nn.Linear(input_dim, h)\n",
    "        self.output_dim = 5\n",
    "        self.W2 = nn.Linear(h, self.output_dim)\n",
    "\n",
    "        self.activation = (\n",
    "            nn.ReLU()\n",
    "        )  # The rectified linear unit; one valid choice of activation function\n",
    "        self.softmax = (\n",
    "            nn.LogSoftmax()\n",
    "        )  # The softmax function that converts vectors into probability distributions; computes log probabilities for computational benefits\n",
    "        self.loss = (\n",
    "            nn.NLLLoss()\n",
    "        )  # The cross-entropy/negative log likelihood loss taught in class\n",
    "\n",
    "    def compute_Loss(self, predicted_vector, gold_label):\n",
    "        return self.loss(predicted_vector, gold_label)\n",
    "\n",
    "    def forward(self, input_vector):\n",
    "        hidden_vector = self.activation(self.W1(input_vector))\n",
    "        output_vector = self.W2(hidden_vector)\n",
    "        predicted_vector = self.softmax(output_vector)\n",
    "        return predicted_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocab(data):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    vocab = A set of strings corresponding to the vocabulary, including the <UNK> token\n",
    "    \"\"\"\n",
    "    return {word for document, _ in data for word in document} | {unk}\n",
    "\n",
    "def make_indices(vocab):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    vocab = A set of strings corresponding to the vocabulary including <UNK>\n",
    "    word2index = A dictionary mapping word/token to its index (a number in 0, ..., V - 1)\n",
    "    index2word = A dictionary inverting the mapping of word2index\n",
    "    \"\"\"\n",
    "    vocab.remove(unk)\n",
    "    vocab_list = sorted(vocab)\n",
    "    \n",
    "    word2index = {word: index for index, word in enumerate(vocab_list)}\n",
    "    word2index[unk] = len(vocab_list)\n",
    "    \n",
    "    index2word = {index: word for index, word in enumerate(vocab_list)}\n",
    "    index2word[len(vocab_list)] = unk\n",
    "    \n",
    "    vocab.add(unk)\n",
    "    return word2index, index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data):\n",
    "    with open(data) as data_f:\n",
    "        data_json = json.load(data_f)\n",
    "\n",
    "    return [(elt[\"text\"].split(), int(elt[\"stars\"] - 1)) for elt in data_json]\n",
    "    \n",
    "def convert_to_vector_representation(data, word2index):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    vectorized_data = A list of pairs (vector representation of input, y)\n",
    "    \"\"\"\n",
    "    vectorized_data = []\n",
    "    for document, y in data:\n",
    "        vector = torch.zeros(len(word2index))\n",
    "        for word in document:\n",
    "            index = word2index.get(word, word2index[unk])\n",
    "            vector[index] += 1\n",
    "        vectorized_data.append((vector, y))\n",
    "    return vectorized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Args:\n",
    "    \"\"\"\n",
    "    hidden_dim (int): hidden dimension\n",
    "    epochs (int): number of epochs to train\n",
    "    train_data (str): path to training data\n",
    "    val_data (str): path to validation data\n",
    "    test_data (str): path to test data\n",
    "    \"\"\"\n",
    "    hidden_dim: int\n",
    "    epochs: int\n",
    "    train_data: str\n",
    "    val_data: str\n",
    "    test_data: str = \"to fill\"\n",
    "    \n",
    "args = Args(\n",
    "    hidden_dim=64,\n",
    "    epochs=10,\n",
    "    train_data=\"training.json\",\n",
    "    val_data=\"validation.json\",\n",
    "    test_data=\"test.json\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7f8cd80a50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix random seeds\n",
    "random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data | X_data is a list of pairs (document, y); y in {0,1,2,3,4}\n",
    "train_data = load_data(args.train_data)\n",
    "valid_data = load_data(args.val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = make_vocab(train_data)\n",
    "word2index, index2word = make_indices(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizing data\n",
    "train_data = convert_to_vector_representation(train_data, word2index)\n",
    "valid_data = convert_to_vector_representation(valid_data, word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size: 8000\n",
      "Validation Data Size: 800\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Size:\", len(train_data))\n",
    "print(\"Validation Data Size:\", len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and optimizer\n",
    "model = FFNN(input_dim=len(vocab), h=args.hidden_dim)\n",
    "model.to(device)  # move model to device\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Training for 10 epochs ==========\n",
      "Training started for epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/home/spenupala/Github_Repos/Personal/College-Work/CS_6320/assignment_2/.venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1518: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "100%|██████████| 500/500 [00:07<00:00, 65.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for epoch 1\n",
      "Training accuracy for epoch 1: 0.792625\n",
      "Validation started for epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 125.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 1\n",
      "Validation accuracy for epoch 1: 0.6125\n",
      "Training started for epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 67.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for epoch 2\n",
      "Training accuracy for epoch 2: 0.79525\n",
      "Validation started for epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 126.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 2\n",
      "Validation accuracy for epoch 2: 0.5925\n",
      "Training started for epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 66.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for epoch 3\n",
      "Training accuracy for epoch 3: 0.857125\n",
      "Validation started for epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 129.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 3\n",
      "Validation accuracy for epoch 3: 0.585\n",
      "Training started for epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 67.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for epoch 4\n",
      "Training accuracy for epoch 4: 0.869875\n",
      "Validation started for epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 129.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 4\n",
      "Validation accuracy for epoch 4: 0.56125\n",
      "Training started for epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 67.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for epoch 5\n",
      "Training accuracy for epoch 5: 0.898875\n",
      "Validation started for epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 130.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 5\n",
      "Validation accuracy for epoch 5: 0.59375\n",
      "Training started for epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 68.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for epoch 6\n",
      "Training accuracy for epoch 6: 0.910375\n",
      "Validation started for epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 129.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 6\n",
      "Validation accuracy for epoch 6: 0.59875\n",
      "Training started for epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 66.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for epoch 7\n",
      "Training accuracy for epoch 7: 0.89275\n",
      "Validation started for epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 129.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 7\n",
      "Validation accuracy for epoch 7: 0.58875\n",
      "Training started for epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 66.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for epoch 8\n",
      "Training accuracy for epoch 8: 0.89225\n",
      "Validation started for epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 128.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 8\n",
      "Validation accuracy for epoch 8: 0.6075\n",
      "Training started for epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 66.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for epoch 9\n",
      "Training accuracy for epoch 9: 0.912375\n",
      "Validation started for epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 126.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 9\n",
      "Validation accuracy for epoch 9: 0.58625\n",
      "Training started for epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:07<00:00, 66.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed for epoch 10\n",
      "Training accuracy for epoch 10: 0.93\n",
      "Validation started for epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 127.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation completed for epoch 10\n",
      "Validation accuracy for epoch 10: 0.57875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training and Validation\n",
    "print(\"========== Training for {} epochs ==========\".format(args.epochs))\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    # optimizer.zero_grad()\n",
    "    \n",
    "    # loss = None\n",
    "    correct = total = 0\n",
    "    random.shuffle(train_data)  # Good practice to shuffle order of training data\n",
    "    N = len(train_data)\n",
    "    minibatch_size = 16\n",
    "    \n",
    "    start_time = time.time()\n",
    "    print(\"Training started for epoch {}\".format(epoch + 1))\n",
    "    for minibatch_index in tqdm(range(N // minibatch_size)):\n",
    "        optimizer.zero_grad()\n",
    "        loss = None\n",
    "        \n",
    "        for example_index in range(minibatch_size):\n",
    "            input_vector, gold_label = train_data[\n",
    "                minibatch_index * minibatch_size + example_index\n",
    "            ]\n",
    "            predicted_vector = model(input_vector.to(device))\n",
    "            predicted_label = torch.argmax(predicted_vector)\n",
    "            correct += int(predicted_label == gold_label)\n",
    "            total += 1\n",
    "            example_loss = model.compute_Loss(\n",
    "                predicted_vector.view(1, -1), torch.tensor([gold_label]).to(device)\n",
    "            )\n",
    "            if loss is None:\n",
    "                loss = example_loss\n",
    "            else:\n",
    "                loss += example_loss\n",
    "                \n",
    "        loss = loss / minibatch_size\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Training completed for epoch {}\".format(epoch + 1))\n",
    "    print(\"Training accuracy for epoch {}: {}\".format(epoch + 1, correct / total))\n",
    "    # print(\"Training time for this epoch: {}\".format(time.time() - start_time))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    # loss = None\n",
    "    correct = total = 0\n",
    "    N = len(valid_data)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        print(\"Validation started for epoch {}\".format(epoch + 1))\n",
    "        for minibatch_index in tqdm(range(N // minibatch_size)):\n",
    "            optimizer.zero_grad()\n",
    "            loss = None\n",
    "            \n",
    "            for example_index in range(minibatch_size):\n",
    "                input_vector, gold_label = valid_data[\n",
    "                    minibatch_index * minibatch_size + example_index\n",
    "                ]\n",
    "                predicted_vector = model(input_vector.to(device))\n",
    "                predicted_label = torch.argmax(predicted_vector)\n",
    "                correct += int(predicted_label == gold_label)\n",
    "                total += 1\n",
    "                example_loss = model.compute_Loss(\n",
    "                    predicted_vector.view(1, -1), torch.tensor([gold_label]).to(device)\n",
    "                )\n",
    "                if loss is None:\n",
    "                    loss = example_loss\n",
    "                else:\n",
    "                    loss += example_loss\n",
    "                    \n",
    "            loss = loss / minibatch_size\n",
    "            \n",
    "        print(\"Validation completed for epoch {}\".format(epoch + 1))\n",
    "        print(\"Validation accuracy for epoch {}: {}\".format(epoch + 1, correct / total))\n",
    "        # print(\"Validation time for this epoch: {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
