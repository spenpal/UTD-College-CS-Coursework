{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import math\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "from string import punctuation\n",
    "from typing import Optional\n",
    "\n",
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsmoothed n-grams\n",
    "\n",
    "To start, you will write a program that computes unsmoothed unigram and bigram probabilities from\n",
    "the training corpus.\n",
    "\n",
    "You are given a tokenized opinion spam corpus as input. You may want to do additional preprocessing, based on the design decisions you make.\n",
    "\n",
    "You may use existing tools just for the purpose of preprocessing, but you must write the code for gathering n-gram counts and computing n-gram probabilities yourself.\n",
    "\n",
    "For example, consider the simple corpus consisting of the sole sentence: \n",
    "\n",
    "`the students like the assignment`\n",
    "\n",
    "Part of what your program would compute for a unigram and bigram model, for example, would be the\n",
    "following:\n",
    "\n",
    "```\n",
    "P (the) = 0.4, P (like) = 0.2\n",
    "P (the|like) = 1.0, P (students|the) = 0.5\n",
    "```\n",
    "\n",
    "**Preprocessing**: The files included are already tokenized and hence it should be straightforward to\n",
    "obtain the tokens by using space as the delimiter. Feel free to do any other preprocessing that you might\n",
    "think is important for this corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in train set\n",
    "with open('./A1_DATASET/train.txt', 'r') as f:\n",
    "    train_text = f.read().splitlines()\n",
    "\n",
    "# Split train set into sentences\n",
    "train_sents = []\n",
    "for line in train_text:\n",
    "    train_sents += sent_tokenize(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am looking at a brick wall , and getting no sleep .'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example train sentence\n",
    "train_sents[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Preprocesses the text by doing the following:\n",
    "    - Removt punctuation\n",
    "    - Convert to lowercase\n",
    "    \"\"\"\n",
    "    text = text.translate(str.maketrans('', '', punctuation))\n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [preprocess(text).split() for text in train_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'looking', 'at', 'a', 'brick', 'wall', 'and', 'getting', 'no', 'sleep']\n"
     ]
    }
   ],
   "source": [
    "# Example preprocessed train sentence\n",
    "print(train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(text: list, n: int) -> list[tuple]:\n",
    "    \"\"\"\n",
    "    Returns a list of n-grams from the text\n",
    "    Includes start and end tokens\n",
    "    \"\"\"\n",
    "    start_tokens = n - 1 if n > 1 else 1\n",
    "    text = ['<s>'] * start_tokens + text + ['</s>']\n",
    "    return [tuple(text[i:i+n]) for i in range(len(text)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute unigrams\n",
    "train_unigrams = [ngrams(sent, 1) for sent in train]\n",
    "train_unigram_counts = reduce(lambda x, y: Counter(x) + Counter(y), train_unigrams)\n",
    "\n",
    "train_total_tokens = sum(train_unigram_counts.values())\n",
    "train_vocab_size = len(train_unigram_counts)\n",
    "train_unigram_probs = {k: v / train_total_tokens for k, v in train_unigram_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<s>',), 5406),\n",
       " (('</s>',), 5406),\n",
       " (('the',), 5302),\n",
       " (('and',), 2593),\n",
       " (('a',), 2247),\n",
       " (('to',), 2090),\n",
       " (('was',), 1826),\n",
       " (('i',), 1711),\n",
       " (('in',), 1260),\n",
       " (('we',), 1117)]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top 10 unigram counts\n",
    "train_unigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<s>',), 0.05992617308310517),\n",
       " (('</s>',), 0.05992617308310517),\n",
       " (('the',), 0.05877332032678942),\n",
       " (('and',), 0.028743723049295542),\n",
       " (('a',), 0.0249082706100143),\n",
       " (('to',), 0.023167906352883794),\n",
       " (('was',), 0.020241433971466893),\n",
       " (('i',), 0.01896664486592544),\n",
       " (('in',), 0.01396725454767157),\n",
       " (('we',), 0.012382082007737416)]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top 10 unigram probabilities\n",
    "sorted(train_unigram_probs.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bigrams\n",
    "train_bigrams = [ngrams(sent, 2) for sent in train]\n",
    "train_bigram_counts = reduce(lambda x, y: Counter(x) + Counter(y), train_bigrams)\n",
    "train_bigram_probs = {k: v / train_unigram_counts[(k[0],)] for k, v in train_bigram_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<s>', 'the'), 991),\n",
       " (('<s>', 'i'), 710),\n",
       " (('<s>', 'we'), 462),\n",
       " (('the', 'hotel'), 414),\n",
       " (('in', 'the'), 412),\n",
       " (('of', 'the'), 343),\n",
       " (('at', 'the'), 333),\n",
       " (('the', 'room'), 295),\n",
       " (('and', 'the'), 281),\n",
       " (('to', 'the'), 264)]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top 10 bigram counts\n",
    "train_bigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pack unigram and bigram counts into a dictionary\n",
    "train_ngram_counts = {\n",
    "    1: train_unigram_counts,\n",
    "    2: train_bigram_counts\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothing and unknown words\n",
    "\n",
    "Firstly, you should implement at least one method to handle unknown words. \n",
    "\n",
    "Then, you will need to implement two smoothing methods (e.g., Laplace, Add-k smoothing) with different values of k. \n",
    "\n",
    "Teams can choose any method(s) they prefer for each. The report should clearly state the selected methods, providing a description for any non-standard approach (e.g., an approach not covered in class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace words with <unk> if they appear less than or equal to \"n\" times\n",
    "n = 1\n",
    "unk_words = {k[0] for k, v in train_unigram_counts.items() if v <= n}\n",
    "\n",
    "# Replace decided unk_words with <UNK> in train set\n",
    "unk_train = [\n",
    "    [\"<UNK>\" if word in unk_words else word for word in sent] for sent in train\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when', 'speaking', 'to', 'the', 'front', 'desk', 'i', 'was', 'told', 'that', 'they', 'were', 'simply', '<UNK>', 'my', 'request', 'for', 'an', 'upper', 'floor', 'which', 'i', 'had', 'requested', 'for', 'a', 'better', 'view']\n"
     ]
    }
   ],
   "source": [
    "# Example sentence with <UNK> tokens\n",
    "for sent in unk_train:\n",
    "    if \"<UNK>\" in sent:\n",
    "        print(sent)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute unigrams\n",
    "train_unk_unigrams = [ngrams(sent, 1) for sent in unk_train]\n",
    "train_unk_unigram_counts = reduce(lambda x, y: Counter(x) + Counter(y), train_unk_unigrams)\n",
    "train_unk_unigram_probs = {k: v / train_total_tokens for k, v in train_unk_unigram_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<s>',), 5406),\n",
       " (('</s>',), 5406),\n",
       " (('the',), 5302),\n",
       " (('<UNK>',), 3113),\n",
       " (('and',), 2593),\n",
       " (('a',), 2247),\n",
       " (('to',), 2090),\n",
       " (('was',), 1826),\n",
       " (('i',), 1711),\n",
       " (('in',), 1260)]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top 10 unigram counts\n",
    "train_unk_unigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<s>',), 0.05992617308310517),\n",
       " (('</s>',), 0.05992617308310517),\n",
       " (('the',), 0.05877332032678942),\n",
       " (('<UNK>',), 0.034507986830874283),\n",
       " (('and',), 0.028743723049295542),\n",
       " (('a',), 0.0249082706100143),\n",
       " (('to',), 0.023167906352883794),\n",
       " (('was',), 0.020241433971466893),\n",
       " (('i',), 0.01896664486592544),\n",
       " (('in',), 0.01396725454767157)]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top 10 unigram probabilities\n",
    "sorted(train_unk_unigram_probs.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute bigrams\n",
    "train_unk_bigrams = [ngrams(sent, 2) for sent in unk_train]\n",
    "train_unk_bigram_counts = reduce(lambda x, y: Counter(x) + Counter(y), train_unk_bigrams)\n",
    "train_unk_bigram_probs = {k: v / train_unk_unigram_counts[(k[0],)] for k, v in train_unk_bigram_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<s>', 'the'), 991),\n",
       " (('<s>', 'i'), 710),\n",
       " (('<s>', 'we'), 462),\n",
       " (('<UNK>', '</s>'), 443),\n",
       " (('the', 'hotel'), 414),\n",
       " (('in', 'the'), 412),\n",
       " (('of', 'the'), 343),\n",
       " (('at', 'the'), 333),\n",
       " (('the', 'room'), 295),\n",
       " (('and', 'the'), 281)]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display top 10 bigram counts\n",
    "train_unk_bigram_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothing(ngram: tuple[str, ...], ngram_counts: dict[int, dict], vocab_size: int, total_tokens: Optional[int] = None) -> float:\n",
    "    \"\"\"\n",
    "    Returns the Laplace smoothed probability for a given ngram\n",
    "    \"\"\"\n",
    "    n = len(ngram)\n",
    "    if n == 1:\n",
    "        return (ngram_counts[1][ngram] + 1) / (total_tokens + vocab_size)\n",
    "    else:\n",
    "        return (ngram_counts[n][ngram] + 1) / (ngram_counts[n-1][ngram[:-1]] + vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_k_smoothing(ngram: tuple[str, ...], ngram_counts: dict[int, dict], vocab_size: int, total_tokens: Optional[int] = None, k: int = 1) -> float:\n",
    "    \"\"\"\n",
    "    Returns the add-k smoothed probability for a given ngram\n",
    "    \"\"\"\n",
    "    n = len(ngram)\n",
    "    if n == 1:\n",
    "        return (ngram_counts[1][ngram] + k) / (total_tokens + k * vocab_size)\n",
    "    else:\n",
    "        return (ngram_counts[n][ngram] + k) / (ngram_counts[n-1][ngram[:-1]] + k * vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perplexity\n",
    "\n",
    "Implement code to compute the perplexity of a `development set` (*A `development set` is just another way to refer to the validation set—part of a dataset distinct from the training portion)*. Compute and report the perplexity of your model (with variations) on it. Compute perplexity as follows:\n",
    "\n",
    "![](https://i.gyazo.com/4069027ef1730b89862b96cbb1526b7e.png)\n",
    "\n",
    "Where:\n",
    "\n",
    "- N is the total number of tokens in the test corpus.\n",
    "- P(w_i|w_i1, ..., w_in+1) is the n-gram probability of your model.\n",
    "\n",
    "Under the second definition above, perplexity is a function of the average (per-word) log probability. Use this to avoid numerical computation errors.\n",
    "\n",
    "If you experimented with more than one type of smoothing and unknown word handling, you should report and compare the perplexity results of experiments among some of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in test set\n",
    "with open('./A1_DATASET/val.txt', 'r') as f:\n",
    "    val_text = f.read().splitlines()\n",
    "    \n",
    "# Split test set into sentences\n",
    "val_sents = []\n",
    "for line in val_text:\n",
    "    val_sents += sent_tokenize(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = [preprocess(text).split() for text in val_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_unigrams = [ngrams(sent, 1) for sent in val]\n",
    "val_bigrams = [ngrams(sent, 2) for sent in val]\n",
    "\n",
    "val_total_tokens = sum([len(sent) for sent in val_unigrams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perplexity(sent_probs: list[float], total_tokens: int, logged: Optional[bool] = False) -> float:\n",
    "    \"\"\"\n",
    "    Returns the perplexity of the test dataset\n",
    "    \"\"\"\n",
    "    if logged:\n",
    "        l = (1 / total_tokens) * sum(sent_probs)\n",
    "    else:\n",
    "        l = (1 / total_tokens) * sum([math.log2(prob) for prob in sent_probs])\n",
    "    return 2 ** -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perplexity For Train Unigrams**\n",
    "\n",
    "4 Methods:\n",
    "- Default model\n",
    "- \\<UNK\\> words\n",
    "- Laplace Smoothing\n",
    "- Add-K Smoothing\n",
    "    - k=0.5\n",
    "    - k=0.05\n",
    "    - k=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Unigrams): 386.9407731234205\n"
     ]
    }
   ],
   "source": [
    "# Default model\n",
    "train_sent_probs = [\n",
    "    sum(math.log2(train_unigram_probs[unigram]) for unigram in sent_unigrams)\n",
    "    for sent_unigrams in train_unigrams\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"(Perplexity | Unigrams):\",\n",
    "    perplexity(train_sent_probs, train_total_tokens, logged=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Unigrams | <UNK>): 293.1581119212855\n"
     ]
    }
   ],
   "source": [
    "# Using <UNK> tokens\n",
    "train_sent_probs_unk = [\n",
    "    sum(math.log2(train_unk_unigram_probs[unigram]) for unigram in sent_unigrams)\n",
    "    for sent_unigrams in train_unk_unigrams\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"(Perplexity | Unigrams | <UNK>):\",\n",
    "    perplexity(train_sent_probs_unk, train_total_tokens, logged=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Unigrams | Laplace Smoothing): 391.5586878701987\n"
     ]
    }
   ],
   "source": [
    "# Using Laplace Smoothing\n",
    "train_sent_probs_lp = [\n",
    "    sum(\n",
    "        math.log2(\n",
    "            laplace_smoothing(\n",
    "                ngram=unigram,\n",
    "                ngram_counts=train_ngram_counts,\n",
    "                vocab_size=train_vocab_size,\n",
    "                total_tokens=train_total_tokens,\n",
    "            )\n",
    "        )\n",
    "        for unigram in sent_unigrams\n",
    "    )\n",
    "    for sent_unigrams in train_unigrams\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"(Perplexity | Unigrams | Laplace Smoothing):\",\n",
    "    perplexity(train_sent_probs_lp, train_total_tokens, logged=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Unigrams | Add-K Smoothing | k=0.5): 388.3597028637293\n",
      "(Perplexity | Unigrams | Add-K Smoothing | k=0.05): 386.9588354529094\n",
      "(Perplexity | Unigrams | Add-K Smoothing | k=0.01): 386.9415141647935\n"
     ]
    }
   ],
   "source": [
    "# Using Add-k Smoothing\n",
    "k = [0.5, 0.05, 0.01]\n",
    "for k_val in k:\n",
    "    train_sent_probs_addk = [\n",
    "        sum(\n",
    "            math.log2(\n",
    "                add_k_smoothing(\n",
    "                    ngram=unigram,\n",
    "                    ngram_counts=train_ngram_counts,\n",
    "                    vocab_size=train_vocab_size,\n",
    "                    total_tokens=train_total_tokens,\n",
    "                    k=k_val,\n",
    "                )\n",
    "            )\n",
    "            for unigram in sent_unigrams\n",
    "        )\n",
    "        for sent_unigrams in train_unigrams\n",
    "    ]\n",
    "    print(\n",
    "        f\"(Perplexity | Unigrams | Add-K Smoothing | k={k_val}):\",\n",
    "        perplexity(train_sent_probs_addk, train_total_tokens, logged=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perplexity For Train Bigrams**\n",
    "\n",
    "4 Methods:\n",
    "- Default model\n",
    "- \\<UNK\\> words\n",
    "- Laplace Smoothing\n",
    "- Add-K Smoothing\n",
    "    - k=0.5\n",
    "    - k=0.05\n",
    "    - k=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Bigrams): 24.25418362940641\n"
     ]
    }
   ],
   "source": [
    "# Default model\n",
    "train_sent_probs = [\n",
    "    sum(math.log2(train_bigram_probs[bigram]) for bigram in sent_bigrams)\n",
    "    for sent_bigrams in train_bigrams\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"(Perplexity | Bigrams):\",\n",
    "    perplexity(train_sent_probs, train_total_tokens, logged=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Bigrams | <UNK> Tokens): 26.208412952642487\n"
     ]
    }
   ],
   "source": [
    "# Using <UNK> tokens\n",
    "train_sent_probs_unk = [\n",
    "    sum(math.log2(train_unk_bigram_probs[bigram]) for bigram in sent_bigrams)\n",
    "    for sent_bigrams in train_unk_bigrams\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"(Perplexity | Bigrams | <UNK> Tokens):\",\n",
    "    perplexity(train_sent_probs_unk, train_total_tokens, logged=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Bigrams | Laplace Smoothing): 543.8729432319209\n"
     ]
    }
   ],
   "source": [
    "# Using Laplace Smoothing\n",
    "train_sent_probs_lp = [\n",
    "    sum(\n",
    "        math.log2(\n",
    "            laplace_smoothing(\n",
    "                ngram=bigram,\n",
    "                ngram_counts=train_ngram_counts,\n",
    "                vocab_size=train_vocab_size,\n",
    "            )\n",
    "        )\n",
    "        for bigram in sent_bigrams\n",
    "    )\n",
    "    for sent_bigrams in train_bigrams\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"(Perplexity | Bigrams | Laplace Smoothing):\",\n",
    "    perplexity(train_sent_probs_lp, train_total_tokens, logged=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Bigrams | Add-K Smoothing | k=0.5): 355.49563626110097\n",
      "(Perplexity | Bigrams | Add-K Smoothing | k=0.05): 94.56777334360764\n",
      "(Perplexity | Bigrams | Add-K Smoothing | k=0.01): 49.32755017057055\n"
     ]
    }
   ],
   "source": [
    "# Using Add-k Smoothing\n",
    "k = [0.5, 0.05, 0.01]\n",
    "for k_val in k:\n",
    "    train_sent_probs_addk = [\n",
    "        sum(\n",
    "            math.log2(\n",
    "                add_k_smoothing(\n",
    "                    ngram=bigram,\n",
    "                    ngram_counts=train_ngram_counts,\n",
    "                    vocab_size=train_vocab_size,\n",
    "                    k=k_val,\n",
    "                )\n",
    "            )\n",
    "            for bigram in sent_bigrams\n",
    "        )\n",
    "        for sent_bigrams in train_bigrams\n",
    "    ]\n",
    "    print(\n",
    "        f\"(Perplexity | Bigrams | Add-K Smoothing | k={k_val}):\",\n",
    "        perplexity(train_sent_probs_addk, train_total_tokens, logged=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perplexity For Validation Unigrams**\n",
    "\n",
    "3 Methods:\n",
    "- \\<UNK\\> words\n",
    "- Laplace Smoothing\n",
    "- Add-K Smoothing\n",
    "    - k=0.5\n",
    "    - k=0.05\n",
    "    - k=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Unigrams | <UNK> Tokens): 259.53523951181285\n"
     ]
    }
   ],
   "source": [
    "# Using <UNK> tokens\n",
    "val_sent_probs_unk = [\n",
    "    math.prod(\n",
    "        train_unk_unigram_probs.get(unigram, train_unk_unigram_probs[(\"<UNK>\",)])\n",
    "        for unigram in sent_unigrams\n",
    "    )\n",
    "    for sent_unigrams in val_unigrams\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"(Perplexity | Unigrams | <UNK> Tokens):\",\n",
    "    perplexity(val_sent_probs_unk, val_total_tokens),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Unigrams | Laplace Smoothing): 405.54114005777086\n"
     ]
    }
   ],
   "source": [
    "# Using Laplace Smoothing\n",
    "val_sent_probs_lp = [\n",
    "    math.prod(\n",
    "        laplace_smoothing(\n",
    "            ngram=unigram,\n",
    "            ngram_counts=train_ngram_counts,\n",
    "            vocab_size=train_vocab_size,\n",
    "            total_tokens=train_total_tokens,\n",
    "        )\n",
    "        for unigram in sent_unigrams\n",
    "    )\n",
    "    for sent_unigrams in val_unigrams\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"(Perplexity | Unigrams | Laplace Smoothing):\",\n",
    "    perplexity(val_sent_probs_lp, val_total_tokens),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Unigrams | Add-K Smoothing | k=0.5): 408.57817450839923\n",
      "(Perplexity | Unigrams | Add-K Smoothing | k=0.05): 434.64146521784977\n",
      "(Perplexity | Unigrams | Add-K Smoothing | k=0.01): 456.93220723622795\n"
     ]
    }
   ],
   "source": [
    "# Using Add-k Smoothing\n",
    "k = [0.5, 0.05, 0.01]\n",
    "for k_val in k:\n",
    "    val_sent_probs_addk = [\n",
    "        math.prod(\n",
    "            add_k_smoothing(\n",
    "                ngram=unigram,\n",
    "                ngram_counts=train_ngram_counts,\n",
    "                vocab_size=train_vocab_size,\n",
    "                total_tokens=train_total_tokens,\n",
    "                k=k_val,\n",
    "            )\n",
    "            for unigram in sent_unigrams\n",
    "        )\n",
    "        for sent_unigrams in val_unigrams\n",
    "    ]\n",
    "    print(\n",
    "        f\"(Perplexity | Unigrams | Add-K Smoothing | k={k_val}):\",\n",
    "        perplexity(val_sent_probs_addk, val_total_tokens),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perplexity For Validation Bigrams**\n",
    "\n",
    "3 Methods:\n",
    "- \\<UNK\\> words\n",
    "- Laplace Smoothing\n",
    "- Add-K Smoothing\n",
    "    - k=0.5\n",
    "    - k=0.05\n",
    "    - k=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Bigrams | <UNK> Tokens): 20.481719165161444\n"
     ]
    }
   ],
   "source": [
    "# Using <UNK> tokens\n",
    "val_sent_probs_unk = [\n",
    "    math.prod(\n",
    "        train_unk_bigram_probs.get(\n",
    "            tuple(\"<UNK>\" if word in unk_words else word for word in bigram),\n",
    "            train_unk_bigram_probs[(\"<UNK>\", \"<UNK>\")],\n",
    "        )\n",
    "        for bigram in sent_bigrams\n",
    "    )\n",
    "    for sent_bigrams in val_bigrams\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"(Perplexity | Bigrams | <UNK> Tokens):\",\n",
    "    perplexity(val_sent_probs_unk, val_total_tokens),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Bigrams | Laplace Smoothing): 705.2629317593495\n"
     ]
    }
   ],
   "source": [
    "# Using Laplace Smoothing\n",
    "val_sent_probs_lp = [\n",
    "    math.prod(\n",
    "        laplace_smoothing(\n",
    "            ngram=bigram, ngram_counts=train_ngram_counts, vocab_size=train_vocab_size\n",
    "        )\n",
    "        for bigram in sent_bigrams\n",
    "    )\n",
    "    for sent_bigrams in val_bigrams\n",
    "]\n",
    "\n",
    "print(\n",
    "    \"(Perplexity | Bigrams | Laplace Smoothing):\",\n",
    "    perplexity(val_sent_probs_lp, val_total_tokens),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Perplexity | Bigrams | Add-K Smoothing | k=0.5): 525.5916751239168\n",
      "(Perplexity | Bigrams | Add-K Smoothing | k=0.05): 252.439489240591\n",
      "(Perplexity | Bigrams | Add-K Smoothing | k=0.01): 209.83712354693142\n"
     ]
    }
   ],
   "source": [
    "# Using Add-k Smoothing\n",
    "k = [0.5, 0.05, 0.01]\n",
    "for k_val in k:\n",
    "    val_sent_probs_k = [\n",
    "        math.prod(\n",
    "            add_k_smoothing(\n",
    "                ngram=bigram,\n",
    "                ngram_counts=train_ngram_counts,\n",
    "                vocab_size=train_vocab_size,\n",
    "                k=k_val,\n",
    "            )\n",
    "            for bigram in sent_bigrams\n",
    "        )\n",
    "        for sent_bigrams in val_bigrams\n",
    "    ]\n",
    "    print(\n",
    "        f\"(Perplexity | Bigrams | Add-K Smoothing | k={k_val}):\",\n",
    "        perplexity(val_sent_probs_k, val_total_tokens),\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
